{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "colab": {
      "name": "60_munites_intro_from_official_site.ipynb",
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "82009a68686d4b85b5ee79a3d2387231": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_21a9280190274cbd82da525245c1c32e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_817e3c73b2af4016b1e44731f896cd83",
              "IPY_MODEL_45903ed34ec14c1ca9e51c6b40e49890"
            ]
          }
        },
        "21a9280190274cbd82da525245c1c32e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "817e3c73b2af4016b1e44731f896cd83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_96f2fb13b70147b4bc2ef0d9e80835c6",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 46827520,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 46827520,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6a68fda430a84e8ca2d6420e591981e7"
          }
        },
        "45903ed34ec14c1ca9e51c6b40e49890": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e861ff62badb4a16af9a702f1c46a2ca",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 44.7M/44.7M [00:55&lt;00:00, 840kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_579739f0b276492f8725b4f2750b6b65"
          }
        },
        "96f2fb13b70147b4bc2ef0d9e80835c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6a68fda430a84e8ca2d6420e591981e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e861ff62badb4a16af9a702f1c46a2ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "579739f0b276492f8725b4f2750b6b65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gz6zp_F0JPUe"
      },
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NK5-Npf4JgCL",
        "outputId": "b6426ca9-2d2a-48e2-ba97-d0b48f80e0e3"
      },
      "source": [
        "torch.__version__"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.8.0+cu101'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pry5tiWFJlKD",
        "outputId": "79115c8c-b088-4543-9ac7-4a9c8ea9e24b"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ip7BESc9JPUi"
      },
      "source": [
        "1. Tensors (torch.Tensor, Tensor Attributes)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1uZLnEtJPUj",
        "outputId": "ea6d0ba2-b176-4af7-9c5f-9a5794f5b569"
      },
      "source": [
        "#from python list or sequence\n",
        "a = [[1_000, 0], [3, 4]]\n",
        "#dtype int8, unsigned int8, int16, int32, int64, float16, float32, float64, boolean\n",
        "x = torch.tensor(a, dtype=torch.bool, device='cpu')\n",
        "x.dtype, x.device, x.stride() #reference to tensor.Storage"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.bool, device(type='cpu'), (2, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gt-EyQ_XJPUk",
        "outputId": "c8f46468-babf-451e-80c4-d652084e7e0f"
      },
      "source": [
        "# 9 cpu constructors with specific dtype [torch.FloatTensor ...]\n",
        "# 9 gpu constructors with specific dtype [torch.cuda.FloatTensor ...]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7u3JYaLSJPUj",
        "outputId": "867d389f-fb3e-4ada-d860-c7cdeb3f603f"
      },
      "source": [
        "# from array_like data\n",
        "a = np.array([[1_000, 0], [3, 4]])\n",
        "q = torch.as_tensor(a) #avoid copy\n",
        "q[0, 0] = -1\n",
        "a[0, 0], q.device\n",
        "#on gpu this trick isn't work"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-1, device(type='cpu'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5D536HjrT1c4"
      },
      "source": [
        "#from numpy (see bridge section)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZnFY2xAMmDh",
        "outputId": "0b213cdc-af1e-4a72-aa48-8814c45c21e7"
      },
      "source": [
        "#from another tensor\n",
        "data = torch.tensor([[1, 2], [3, 4]])\n",
        "x_ones = torch.ones_like(data)\n",
        "\n",
        "x_rand = torch.rand_like(data, dtype=torch.float16)\n",
        "\n",
        "x_ones, x_ones.dtype, x_rand, x_rand.dtype"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1, 1],\n",
              "         [1, 1]]), torch.int64, tensor([[0.7793, 0.8838],\n",
              "         [0.1787, 0.9209]], dtype=torch.float16), torch.float16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyRqxW1XJPUk",
        "outputId": "667e6dd9-b5e1-4ebe-dfc7-aeced2006780"
      },
      "source": [
        "#numpy axis is equal to torch dim\n",
        "a = np.array([[[1, 2, 3], \n",
        "               [3, 4, 0]],\n",
        "                        [[1, 2, 3], \n",
        "                        [3, 4, 0]]])\n",
        "a.shape, a.sum(axis=0), a.sum(axis=1), a.sum(axis=2)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2, 2, 3), array([[2, 4, 6],\n",
              "        [6, 8, 0]]), array([[4, 6, 3],\n",
              "        [4, 6, 3]]), array([[6, 7],\n",
              "        [6, 7]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C09HfQyOJPUk",
        "outputId": "4c9b0b59-a600-4025-a53c-20dc0f539f23"
      },
      "source": [
        "b = torch.tensor(a)\n",
        "b.sum(dim=0), b.sum(dim=1), b.sum(dim=2)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[2, 4, 6],\n",
              "         [6, 8, 0]]), tensor([[4, 6, 3],\n",
              "         [4, 6, 3]]), tensor([[6, 7],\n",
              "         [6, 7]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJ4ABpTcPnFR",
        "outputId": "d43fd59e-57c9-4221-c772-fb9828ce91e4"
      },
      "source": [
        "# tensor operations\n",
        "# that have a _ suffix are in-place\n",
        "#x.copy_(y)\n",
        "#x.t_()\n",
        "tensor = torch.ones((3, 3))\n",
        "tensor.add_(5)\n",
        "tensor"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[6., 6., 6.],\n",
              "        [6., 6., 6.],\n",
              "        [6., 6., 6.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5uGJEHvSKOA",
        "outputId": "03c99ae3-f7dc-438c-c0f2-83d136e5f9a4"
      },
      "source": [
        "#numpy pytorch bridge\n",
        "#Tensors on the CPU and NumPy arrays can share their underlying memory locations, and changing one will change the other.\n",
        "  # torch -> numpy\n",
        "t = torch.ones(5)\n",
        "n = t.numpy()\n",
        "t, n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 1., 1., 1., 1.]), array([1., 1., 1., 1., 1.], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2l1PK-SwSvzM",
        "outputId": "53c13dc3-c3e3-4e30-caeb-d58fe5ee55f7"
      },
      "source": [
        "t.add_(5)\n",
        "t, n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([6., 6., 6., 6., 6.]), array([6., 6., 6., 6., 6.], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56wjZ_2XT7mP",
        "outputId": "8e67f6fb-05ae-4e13-93f8-09e1c6779c3e"
      },
      "source": [
        "  #numpy -> torch\n",
        "n = np.ones(3)\n",
        "t = torch.from_numpy(n)\n",
        "n, t"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1., 1., 1.]), tensor([1., 1., 1.], dtype=torch.float64))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJPFMvktUsBX",
        "outputId": "6b2a7ad8-0286-4c8f-ccbd-c4583ca744f4"
      },
      "source": [
        "np.add(n, 1, out=n)\n",
        "n, t"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([2., 2., 2.]), tensor([2., 2., 2.], dtype=torch.float64))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJwEg7ONJPUl"
      },
      "source": [
        "2. torch.Autograd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wr9W2r2yJPUl",
        "outputId": "9e855bbb-79d0-47d8-b4b2-27c57c1ad305"
      },
      "source": [
        "#torch autograd\n",
        "  #out = t^2\n",
        "t = torch.tensor([1, 2, 3], dtype=torch.float32, requires_grad=True)\n",
        "out = t.pow(2)\n",
        "out, t.shape"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 4., 9.], grad_fn=<PowBackward0>), torch.Size([3]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5TIR3ErZEtX"
      },
      "source": [
        "  #When we call .backward() on OUT, autograd calculates these gradients and stores them in the respective tensor's .grad attribute.\n",
        "  #We need to explicitly pass a gradient argument in OUT.backward() because it is a vector. gradient is a tensor of the same shape as OUT, and it represents the gradient of the OUT itself\n",
        "out.backward(gradient=torch.tensor([1, 1, 1]))"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwbgGQzkZuwm",
        "outputId": "3f795457-2b3f-431f-cf8b-d298ed3ea21e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "t.grad"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 4., 6.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nL1p9yUoZ8Eh",
        "outputId": "86138749-076b-41a8-d8d9-1a88874efb39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "  #Equivalently, we can aggregate Q into a scalar and call backward implicitly [grad can be implicitly created only for scalar outputs]\n",
        "t = torch.tensor([1, 2, 3], dtype=torch.float32, requires_grad=True)\n",
        "out2 = t.pow(2).sum()\n",
        "out2"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14., grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgWiYahZ9lb_",
        "outputId": "c46f5dba-6142-4d9d-991b-cae4ac6d5365",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "out2.backward()\n",
        "t.grad"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 4., 6.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxrf18QR6joq",
        "outputId": "2f718fee-534a-4d4c-e89d-5948c18aea94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "out2.grad_fn"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SumBackward0 at 0x7fa5f1699110>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyMHv09JCqkq"
      },
      "source": [
        "  # Pytorch support differentiation of a scalar functions (self derivative is 1), os if we want too start backward from a non-scalar value, we provide torch.tensor in backward(gradient=...)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT6aZRZRCqlo"
      },
      "source": [
        "  #Example 2\n",
        "a = torch.tensor([2., 3.], requires_grad=True)\n",
        "b = torch.tensor([6., 4.], requires_grad=True)\n",
        "Q = 3*a**3 - b**2"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drOS8T79FcjA"
      },
      "source": [
        "Q.backward(gradient=torch.tensor([1., 1.]))"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieAqLeByFlCx",
        "outputId": "679d37f0-188a-418c-9de9-fdf932edbca4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(9*a**2 == a.grad)\n",
        "print(-2*b == b.grad)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([True, True])\n",
            "tensor([True, True])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VO9yGCfPFxhn"
      },
      "source": [
        "  #Generally speaking, torch.autograd is an engine for computing vector-Jacobian product. That is, given any vector v, compute the product J.T * v (see perfect example in doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLPSElosKlu4"
      },
      "source": [
        "3. Computational Graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJEbZe_NKuJ9"
      },
      "source": [
        "Conceptually, autograd keeps a record of data (tensors) and all executed operations (along with the resulting tensors) in a **directed acyclic graph DAG** consisting of a autograd.Function objects. In this DAG, leaves are the input tensors, roots are the output tensors. By tracking this graph from roots to leaves, you can automatically compute the gradients using the chain rule.\n",
        "\n",
        "\n",
        "In a forward pass, autograd does twoo things simultaneously:\n",
        "  - run the requested operation to compute a resulting tensor\n",
        "  - maintain the operation's gradient function in the DAG\n",
        "\n",
        "The backward pass kicks off when .backward is called on the DAG root. autograd then:\n",
        "  - computes the gradients from each .grad_fn\n",
        "  - accumulates them in the respective tensor's .grad attribute\n",
        "  - using the chain rule, propagates all the way to the leaf tensors\n",
        "\n",
        "**DAGs are dynamic in PyTorch and, after .backward() call, autograd starts populate a new graph.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UekeMb-0KlLr"
      },
      "source": [
        "  #Exclusion from the DAG - requires_grad = False (frozen parameters - we dont need their parameters)\n",
        "  #is important for funetuning a pretrained network"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fOI0M5gPJS2",
        "outputId": "9151f3af-1839-4b57-b673-a13513a436ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "82009a68686d4b85b5ee79a3d2387231",
            "21a9280190274cbd82da525245c1c32e",
            "817e3c73b2af4016b1e44731f896cd83",
            "45903ed34ec14c1ca9e51c6b40e49890",
            "96f2fb13b70147b4bc2ef0d9e80835c6",
            "6a68fda430a84e8ca2d6420e591981e7",
            "e861ff62badb4a16af9a702f1c46a2ca",
            "579739f0b276492f8725b4f2750b6b65"
          ]
        }
      },
      "source": [
        "from torch import nn, optim\n",
        "import torchvision\n",
        "\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "#freeze all the parameters in the network\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82009a68686d4b85b5ee79a3d2387231",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-xQuzD9Qc-1"
      },
      "source": [
        "let's say we want to finetune the model on a new dataset with 10 label. In resnet, the classifier is the last linear layer model.fc. We can simply replace it with a new linear layer (unfrose by default)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxDQeHRbQeCH"
      },
      "source": [
        "model.fc = nn.Linear(512, 10)"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gh6v11WQnBS"
      },
      "source": [
        "#optimize only the classifier\n",
        "optimizer = optim.SGD(model.fc.parameters(), lr=1e-2, momentum=0.9)\n",
        "#same functionality is available as a context manager in torch.no_grad()"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjGIHzgLRX9w"
      },
      "source": [
        "4. Neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMrs2zbJRa_a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}