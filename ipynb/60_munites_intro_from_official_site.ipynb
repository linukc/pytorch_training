{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "colab": {
      "name": "60_munites_intro_from_official_site.ipynb",
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "82009a68686d4b85b5ee79a3d2387231": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_21a9280190274cbd82da525245c1c32e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_817e3c73b2af4016b1e44731f896cd83",
              "IPY_MODEL_45903ed34ec14c1ca9e51c6b40e49890"
            ]
          }
        },
        "21a9280190274cbd82da525245c1c32e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "817e3c73b2af4016b1e44731f896cd83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_96f2fb13b70147b4bc2ef0d9e80835c6",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 46827520,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 46827520,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6a68fda430a84e8ca2d6420e591981e7"
          }
        },
        "45903ed34ec14c1ca9e51c6b40e49890": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e861ff62badb4a16af9a702f1c46a2ca",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 44.7M/44.7M [00:55&lt;00:00, 840kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_579739f0b276492f8725b4f2750b6b65"
          }
        },
        "96f2fb13b70147b4bc2ef0d9e80835c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6a68fda430a84e8ca2d6420e591981e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e861ff62badb4a16af9a702f1c46a2ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "579739f0b276492f8725b4f2750b6b65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gz6zp_F0JPUe"
      },
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NK5-Npf4JgCL",
        "outputId": "b6426ca9-2d2a-48e2-ba97-d0b48f80e0e3"
      },
      "source": [
        "torch.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.8.0+cu101'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pry5tiWFJlKD",
        "outputId": "79115c8c-b088-4543-9ac7-4a9c8ea9e24b"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ip7BESc9JPUi"
      },
      "source": [
        "1. Tensors (torch.Tensor, Tensor Attributes)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1uZLnEtJPUj",
        "outputId": "ea6d0ba2-b176-4af7-9c5f-9a5794f5b569"
      },
      "source": [
        "#from python list or sequence\n",
        "a = [[1_000, 0], [3, 4]]\n",
        "#dtype int8, unsigned int8, int16, int32, int64, float16, float32, float64, boolean\n",
        "x = torch.tensor(a, dtype=torch.bool, device='cpu')\n",
        "x.dtype, x.device, x.stride() #reference to tensor.Storage"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.bool, device(type='cpu'), (2, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gt-EyQ_XJPUk",
        "outputId": "c8f46468-babf-451e-80c4-d652084e7e0f"
      },
      "source": [
        "# 9 cpu constructors with specific dtype [torch.FloatTensor ...]\n",
        "# 9 gpu constructors with specific dtype [torch.cuda.FloatTensor ...]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7u3JYaLSJPUj",
        "outputId": "867d389f-fb3e-4ada-d860-c7cdeb3f603f"
      },
      "source": [
        "# from array_like data\n",
        "a = np.array([[1_000, 0], [3, 4]])\n",
        "q = torch.as_tensor(a) #avoid copy\n",
        "q[0, 0] = -1\n",
        "a[0, 0], q.device\n",
        "#on gpu this trick isn't work"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-1, device(type='cpu'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5D536HjrT1c4"
      },
      "source": [
        "#from numpy (see bridge section)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZnFY2xAMmDh",
        "outputId": "0b213cdc-af1e-4a72-aa48-8814c45c21e7"
      },
      "source": [
        "#from another tensor\n",
        "data = torch.tensor([[1, 2], [3, 4]])\n",
        "x_ones = torch.ones_like(data)\n",
        "\n",
        "x_rand = torch.rand_like(data, dtype=torch.float16)\n",
        "\n",
        "x_ones, x_ones.dtype, x_rand, x_rand.dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1, 1],\n",
              "         [1, 1]]), torch.int64, tensor([[0.7793, 0.8838],\n",
              "         [0.1787, 0.9209]], dtype=torch.float16), torch.float16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyRqxW1XJPUk",
        "outputId": "667e6dd9-b5e1-4ebe-dfc7-aeced2006780"
      },
      "source": [
        "#numpy axis is equal to torch dim\n",
        "a = np.array([[[1, 2, 3], \n",
        "               [3, 4, 0]],\n",
        "                        [[1, 2, 3], \n",
        "                        [3, 4, 0]]])\n",
        "a.shape, a.sum(axis=0), a.sum(axis=1), a.sum(axis=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2, 2, 3), array([[2, 4, 6],\n",
              "        [6, 8, 0]]), array([[4, 6, 3],\n",
              "        [4, 6, 3]]), array([[6, 7],\n",
              "        [6, 7]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C09HfQyOJPUk",
        "outputId": "4c9b0b59-a600-4025-a53c-20dc0f539f23"
      },
      "source": [
        "b = torch.tensor(a)\n",
        "b.sum(dim=0), b.sum(dim=1), b.sum(dim=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[2, 4, 6],\n",
              "         [6, 8, 0]]), tensor([[4, 6, 3],\n",
              "         [4, 6, 3]]), tensor([[6, 7],\n",
              "         [6, 7]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJ4ABpTcPnFR",
        "outputId": "d43fd59e-57c9-4221-c772-fb9828ce91e4"
      },
      "source": [
        "# tensor operations\n",
        "# that have a _ suffix are in-place\n",
        "#x.copy_(y)\n",
        "#x.t_()\n",
        "tensor = torch.ones((3, 3))\n",
        "tensor.add_(5)\n",
        "tensor"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[6., 6., 6.],\n",
              "        [6., 6., 6.],\n",
              "        [6., 6., 6.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5uGJEHvSKOA",
        "outputId": "03c99ae3-f7dc-438c-c0f2-83d136e5f9a4"
      },
      "source": [
        "#numpy pytorch bridge\n",
        "#Tensors on the CPU and NumPy arrays can share their underlying memory locations, and changing one will change the other.\n",
        "  # torch -> numpy\n",
        "t = torch.ones(5)\n",
        "n = t.numpy()\n",
        "t, n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 1., 1., 1., 1.]), array([1., 1., 1., 1., 1.], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2l1PK-SwSvzM",
        "outputId": "53c13dc3-c3e3-4e30-caeb-d58fe5ee55f7"
      },
      "source": [
        "t.add_(5)\n",
        "t, n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([6., 6., 6., 6., 6.]), array([6., 6., 6., 6., 6.], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56wjZ_2XT7mP",
        "outputId": "8e67f6fb-05ae-4e13-93f8-09e1c6779c3e"
      },
      "source": [
        "  #numpy -> torch\n",
        "n = np.ones(3)\n",
        "t = torch.from_numpy(n)\n",
        "n, t"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1., 1., 1.]), tensor([1., 1., 1.], dtype=torch.float64))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJPFMvktUsBX",
        "outputId": "6b2a7ad8-0286-4c8f-ccbd-c4583ca744f4"
      },
      "source": [
        "np.add(n, 1, out=n)\n",
        "n, t"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([2., 2., 2.]), tensor([2., 2., 2.], dtype=torch.float64))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJwEg7ONJPUl"
      },
      "source": [
        "2. torch.Autograd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wr9W2r2yJPUl",
        "outputId": "9e855bbb-79d0-47d8-b4b2-27c57c1ad305"
      },
      "source": [
        "#torch autograd\n",
        "  #out = t^2\n",
        "t = torch.tensor([1, 2, 3], dtype=torch.float32, requires_grad=True)\n",
        "out = t.pow(2)\n",
        "out, t.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 4., 9.], grad_fn=<PowBackward0>), torch.Size([3]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5TIR3ErZEtX"
      },
      "source": [
        "  #When we call .backward() on OUT, autograd calculates these gradients and stores them in the respective tensor's .grad attribute.\n",
        "  #We need to explicitly pass a gradient argument in OUT.backward() because it is a vector. gradient is a tensor of the same shape as OUT, and it represents the gradient of the OUT itself\n",
        "out.backward(gradient=torch.tensor([1, 1, 1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwbgGQzkZuwm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f795457-2b3f-431f-cf8b-d298ed3ea21e"
      },
      "source": [
        "t.grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 4., 6.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nL1p9yUoZ8Eh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86138749-076b-41a8-d8d9-1a88874efb39"
      },
      "source": [
        "  #Equivalently, we can aggregate Q into a scalar and call backward implicitly [grad can be implicitly created only for scalar outputs]\n",
        "t = torch.tensor([1, 2, 3], dtype=torch.float32, requires_grad=True)\n",
        "out2 = t.pow(2).sum()\n",
        "out2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14., grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgWiYahZ9lb_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c46f5dba-6142-4d9d-991b-cae4ac6d5365"
      },
      "source": [
        "out2.backward()\n",
        "t.grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 4., 6.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxrf18QR6joq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f718fee-534a-4d4c-e89d-5948c18aea94"
      },
      "source": [
        "out2.grad_fn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SumBackward0 at 0x7fa5f1699110>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyMHv09JCqkq"
      },
      "source": [
        "  # Pytorch support differentiation of a scalar functions (self derivative is 1), os if we want too start backward from a non-scalar value, we provide torch.tensor in backward(gradient=...)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT6aZRZRCqlo"
      },
      "source": [
        "  #Example 2\n",
        "a = torch.tensor([2., 3.], requires_grad=True)\n",
        "b = torch.tensor([6., 4.], requires_grad=True)\n",
        "Q = 3*a**3 - b**2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drOS8T79FcjA"
      },
      "source": [
        "Q.backward(gradient=torch.tensor([1., 1.]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieAqLeByFlCx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "679d37f0-188a-418c-9de9-fdf932edbca4"
      },
      "source": [
        "print(9*a**2 == a.grad)\n",
        "print(-2*b == b.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([True, True])\n",
            "tensor([True, True])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VO9yGCfPFxhn"
      },
      "source": [
        "  #Generally speaking, torch.autograd is an engine for computing vector-Jacobian product. That is, given any vector v, compute the product J.T * v (see perfect example in doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLPSElosKlu4"
      },
      "source": [
        "3. Computational Graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJEbZe_NKuJ9"
      },
      "source": [
        "Conceptually, autograd keeps a record of data (tensors) and all executed operations (along with the resulting tensors) in a **directed acyclic graph DAG** consisting of a autograd.Function objects. In this DAG, leaves are the input tensors, roots are the output tensors. By tracking this graph from roots to leaves, you can automatically compute the gradients using the chain rule.\n",
        "\n",
        "\n",
        "In a forward pass, autograd does twoo things simultaneously:\n",
        "  - run the requested operation to compute a resulting tensor\n",
        "  - maintain the operation's gradient function in the DAG\n",
        "\n",
        "The backward pass kicks off when .backward is called on the DAG root. autograd then:\n",
        "  - computes the gradients from each .grad_fn\n",
        "  - accumulates them in the respective tensor's .grad attribute\n",
        "  - using the chain rule, propagates all the way to the leaf tensors\n",
        "\n",
        "**DAGs are dynamic in PyTorch and, after .backward() call, autograd starts populate a new graph.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UekeMb-0KlLr"
      },
      "source": [
        "  #Exclusion from the DAG - requires_grad = False (frozen parameters - we dont need their parameters)\n",
        "  #is important for funetuning a pretrained network"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fOI0M5gPJS2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "82009a68686d4b85b5ee79a3d2387231",
            "21a9280190274cbd82da525245c1c32e",
            "817e3c73b2af4016b1e44731f896cd83",
            "45903ed34ec14c1ca9e51c6b40e49890",
            "96f2fb13b70147b4bc2ef0d9e80835c6",
            "6a68fda430a84e8ca2d6420e591981e7",
            "e861ff62badb4a16af9a702f1c46a2ca",
            "579739f0b276492f8725b4f2750b6b65"
          ]
        },
        "outputId": "9151f3af-1839-4b57-b673-a13513a436ae"
      },
      "source": [
        "from torch import nn, optim\n",
        "import torchvision\n",
        "\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "#freeze all the parameters in the network\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82009a68686d4b85b5ee79a3d2387231",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-xQuzD9Qc-1"
      },
      "source": [
        "let's say we want to finetune the model on a new dataset with 10 label. In resnet, the classifier is the last linear layer model.fc. We can simply replace it with a new linear layer (unfrose by default)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxDQeHRbQeCH"
      },
      "source": [
        "model.fc = nn.Linear(512, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gh6v11WQnBS"
      },
      "source": [
        "#optimize only the classifier\n",
        "optimizer = optim.SGD(model.fc.parameters(), lr=1e-2, momentum=0.9)\n",
        "#same functionality is available as a context manager in torch.no_grad()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjGIHzgLRX9w"
      },
      "source": [
        "4. Neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32XVsCJav8tn"
      },
      "source": [
        "A typical trainig procedure for a nn is as follows:\n",
        "  - define the neural network that has some learnable parameters (as weights)\n",
        "  - iterate over a dataset or inputs\n",
        "  - process input through the network\n",
        "  - compute the loss\n",
        "  - propagate gradients back into hte network's parameters \n",
        "  - update the weights  of the network, typically using a smiple update rule: weight-=lr*gradients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMrs2zbJRa_a"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Imn8hblExUwh",
        "outputId": "9e7ebfa0-9238-425f-bddc-c60bcea822dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(1, 6, 3)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 3)\n",
        "    self.fc1 = nn.Linear(16 * 6 * 6, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "    x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "    x = x.view(-1, self.num_flat_features(x))\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "  def num_flat_features(self, x):\n",
        "    size = x.size()[1:]\n",
        "    num_features = 1\n",
        "    for s in size:\n",
        "      num_features *= s\n",
        "    #print(num_features) == 576 in our case\n",
        "    return num_features\n",
        "\n",
        "net = Net()\n",
        "print(net)    "
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8BcGjcBxRzA"
      },
      "source": [
        "##### view #####\n",
        "tensor = torch.tensor([[1, 2], [3, 4]])\n",
        "b = tensor.view((-1, 4)) # -1 mean inferred (предполагаемый == досчитай сам это очевидно)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gq-9h8r4xSn_",
        "outputId": "8daa71e3-9745-40e0-99df-e3e15c8762b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "b.storage().data_ptr() == tensor.storage().data_ptr()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P37tjwegv9_B",
        "outputId": "1962c46b-012f-4c7e-d065-cf3fcd374bb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "b, tensor"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1, 2, 3, 4]]), tensor([[1, 2],\n",
              "         [3, 4]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wF1j9rXHv-E5"
      },
      "source": [
        "################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUUefFmDv-Kf",
        "outputId": "a2756fa1-fa1c-464e-d40c-e204fe30058c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#learnable parameters\n",
        "params = list(net.parameters())\n",
        "len(params), params[0].size()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, torch.Size([6, 1, 3, 3]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMIcZbDqv-MM",
        "outputId": "0e23979d-66c1-4af9-c767-44daf1fce906",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "params[0].__class__"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.nn.parameter.Parameter"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1GoDnPh8cXX",
        "outputId": "b50397ad-a4b8-4f58-ae8a-663913f8b564",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "input = torch.randn(1, 1, 32, 32)\n",
        "out = net(input)\n",
        "print(out)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "576\n",
            "tensor([[-0.1896, -0.0440, -0.0467,  0.0132,  0.0551, -0.1311,  0.0959, -0.0061,\n",
            "         -0.1312,  0.0648]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdHSjpo3-exh"
      },
      "source": [
        "net.zero_grad()\n",
        "out.backward(torch.randn(1, 10))"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juMEVNvt-Lsj"
      },
      "source": [
        "# Loss function"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QgStf1O-Zhc",
        "outputId": "fb47f118-087c-40e0-b5c2-762736019ba8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "output = net(input)\n",
        "target = torch.randn(10)  # a dummy target, for example\n",
        "target = target.view(1, -1)  # make it the same shape as output\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "print(output.shape, target.shape)\n",
        "loss = criterion(output, target)\n",
        "print(loss)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 10]) torch.Size([1, 10])\n",
            "tensor(1.1860, grad_fn=<MseLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V69QHR_5_6Gm"
      },
      "source": [
        "input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d\n",
        "      -> view -> linear -> relu -> linear -> relu -> linear\n",
        "      -> MSELoss\n",
        "      -> loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NHlhCQO_1hd",
        "outputId": "90e0edd2-00e0-4511-95e7-8d0149c0c3a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(loss.grad_fn)  # MSELoss\n",
        "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
        "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<MseLossBackward object at 0x7ff20e687390>\n",
            "<AddmmBackward object at 0x7ff20e6b1850>\n",
            "<AccumulateGrad object at 0x7ff20e687390>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcbpG6hZ_-wp"
      },
      "source": [
        "def print_graph(grad_fn):\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}